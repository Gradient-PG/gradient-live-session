{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_ML1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSB-ncV7F4NB"
      },
      "source": [
        "# ***Intro to ML1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fJ4S7naRubk"
      },
      "source": [
        "## ***Wprowadzenie***\n",
        "\n",
        "W tym notatniku przedstawię przykładową implementację metod opisanych podczas wykładu przy użyciu zaprojektowanych w tym celu popularnych bibliotek języka Python.\n",
        "\n",
        "Omówiona zostanie regresja i klasyfikacja, a także zaimplementowane i dostępne w gotowych bibliotekach metody przeznaczone do tworzenia i treningu modeli uczenia maszynowego. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x4oq2oMSoOE"
      },
      "source": [
        "## ***Wykorzystywane biblioteki***\n",
        "\n",
        "**Numpy** - to biblioteka programistyczna dla języka Python, dodająca obsługę dużych, wielowymiarowych tabel i macierzy.\n",
        "\n",
        "**Scikit-learn** - Scikit-learn to bezpłatna biblioteka do uczenia maszynowego języka programowania Python. Zawiera różne algorytmy klasyfikacji, regresji a także metody pozwalające na automatyzację przebiegu treningu modeli."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os-NzVYCSmn7"
      },
      "source": [
        "## ***Regresja***\n",
        "Celem regresji jest predykcja dla podanych danych wartości ciągłych lub uporządkowanych czyli wartości z dziedziny liczb rzeczywistych.\n",
        "\n",
        "Przykładem regresji może być predykcja cen laptopów, cen mieszkań na rynku czy poziomu cukru we krwi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uQSfloLTA-K"
      },
      "source": [
        "### ***Dane***\n",
        "Najpierw przygotujmy proste dane uczące.\n",
        "\n",
        "Będą to dane reprezentujące parametry poszczególnych laptopów (jako macierz X) i ich ceny (wektor etykiet y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsmfDdmfTrGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835f8259-0366-48ee-a54d-985c15beaa2b"
      },
      "source": [
        "# import biblioteki numpy\n",
        "import numpy as np\n",
        "\n",
        "# Nasze dane jako wektory 4 wartości = [RAM, GPU VRAM, liczba rdzeni CPU, taktowanie CPU]\n",
        "data = np.array([[8., 0., 4., 2.4],\n",
        "        [16., 6., 8., 2.5],\n",
        "        [8., 2., 8., 2.3],\n",
        "        [16., 8., 8., 3.0],\n",
        "        [32., 12., 16., 3.8]])\n",
        "\n",
        "# Nasze etykiety - ceny poszczególnych laptopów\n",
        "prices = np.array([1500., 3000., 1900., 5000., 11000.])\n",
        "\n",
        "# Szybki podgląd całości danych\n",
        "print(data)\n",
        "print(prices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.   0.   4.   2.4]\n",
            " [16.   6.   8.   2.5]\n",
            " [ 8.   2.   8.   2.3]\n",
            " [16.   8.   8.   3. ]\n",
            " [32.  12.  16.   3.8]]\n",
            "[ 1500.  3000.  1900.  5000. 11000.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zH5D5XcTC1P"
      },
      "source": [
        "### ***Hipoteza***\n",
        "\n",
        "Poniżej zaimplementujemy hipotezę czyli funkcję za pomocą której nasz 'model' będzie wyliczał ceny dla nowych danych, które otrzyma na wejściu.\n",
        "\n",
        "Hipoteza ma postać h(x) = a*x4 + b*x3 + c*x2 + d*x1 + e\n",
        "\n",
        "Model uczy się na danych zmieniając wartość swoich parametrów, które zawarte są w wektorze theta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVC7tfueTrzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083f5c34-a24b-471c-c200-e17b7f2dc7fd"
      },
      "source": [
        "# wektor parametrów hipotezy theta [a, b, c, d, e]\n",
        "theta = [100, 150, 200, 100]\n",
        "\n",
        "# hipoteza h(x) = a*x4 + b*x3 + c*x2 + d*x1 + e\n",
        "vector_h = []\n",
        "\n",
        "# obliczenie hipotezy dla każdego przykładu danych\n",
        "for x in data:\n",
        "    h = theta[0] * x[3] + theta[1] * x[2] + theta[2] * x[1] + theta[1] * x[0] + theta[0]\n",
        "    vector_h.append(h)\n",
        "\n",
        "print(vector_h)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2140.0, 5150.0, 3130.0, 5600.0, 10080.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlF5zAYXTE4_"
      },
      "source": [
        "### ***Funkcja kosztu***\n",
        "\n",
        "Nasza funkcja kosztu to tak zwany MSE (*ang. Mean Squared Error*) czyli funkcja *błędu średniokwadratowego*.\n",
        "\n",
        "Wzór tej funkcji jest następujący:\n",
        "\n",
        "L(y, y_pred) = 1/n * sum((y - y_pred)^2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GutmAvXnTsah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714954e0-05b4-4ef5-b3ce-b2d3e52ca13c"
      },
      "source": [
        "# Funckja kosztu L = 1/n * sum((y - y_pred)^2)\n",
        "L = np.sum(np.power(prices - vector_h, 2)) / prices.shape[0]\n",
        "\n",
        "# wyświetlamy wartość naszej funkcji kosztu\n",
        "print(L)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1550280.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqLJIeetTMav"
      },
      "source": [
        "### ***Metoda gradientu prostego***\n",
        "\n",
        "TODO\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyu6YyijF2Mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7e23e1-c345-439d-9e1f-1d730fdce35e"
      },
      "source": [
        "optimize = np.power(prices - vector_h, 2) / prices.shape[0]\n",
        "gradient = np.gradient(optimize)\n",
        "print(optimize)\n",
        "print(gradient)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 81920. 924500. 302580.  72000. 169280.]\n",
            "[ 842580.  110330. -426250.  -66650.   97280.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGrJNK7vIVkw"
      },
      "source": [
        "### ***Przykład z użyciem gotowych danych i funkcji***\n",
        "W praktyce nie ma sensu zawsze implementować powyższych funkcji na nowo. Zamiast z tego korzysta się z już gotowych implementacji, dostępnych w bilbiotekach danego języka programowania.\n",
        "W tym notatniku przedstawię funkcje z biblioteki [scikit-learn](https://scikit-learn.org/stable/index.html), odpowiadające za tworzenie modeli, podział zbiorów danych czy uczenie tych modeli.\n",
        "\n",
        "Biblioteka ta udostępnia również gotowe zbiory danych, zarówno do regresji jak i klasufikacji, na których mozna przeprowadzać testy opracowywanych algorytmów: https://scikit-learn.org/stable/datasets/toy_dataset.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYfnzh_pOMdR"
      },
      "source": [
        "W przypadku regresji skorzystamy ze zbioru diabetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2c0xl1XI8ay",
        "outputId": "94353f68-952c-42e6-9fc3-05ed57f30413"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "# Załadujmy zbiór w celu wyświetlenia listy parametrów służących do opisu danych \n",
        "diabetes = load_diabetes()\n",
        "print(diabetes.feature_names)\n",
        "\n",
        "# W celu łatwiejszej pracy z danymi korzystamy z parametru return_X_y, który\n",
        "# zwraca nam nam dane w postaci macierzy X i wektor etykiet y\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# wyświetlmy rozmiar danych, a także przykładowe wartości\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X[0])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n",
            "[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
            " -0.04340085 -0.00259226  0.01990842 -0.01764613]\n",
            "151.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAGlDOM5UbCx"
      },
      "source": [
        "Jako model wykorzystamy model SGD (*ang. Stochastic Gradient Descent*) [link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) czyli model wykorzystujący odmianę metody gradientu prostego do wyliczania wartości y_pred. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaCBYNeQUbsR",
        "outputId": "b4f8232e-27f4-481a-f162-0fab79433258"
      },
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
        "# wyświetlamy utworzony model w celu podglądu parametrów\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
            "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
            "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
            "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
            "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
            "             warm_start=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mhr0VmkY-4_"
      },
      "source": [
        "W tej komórce wykorzystamy wbudowaną funkcję [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) pozwalającą na automatyzację procesu podziału zbioru na dane treningowe i testowe.\n",
        "\n",
        "Do określenia skuteczności modelu wykorzystany właśnie funkcję MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsDHlC6KY_gQ",
        "outputId": "efa6ec3a-d0c3-4d7e-fa71-4cf301eecbee"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# podział zbioru na zbiór treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
        "\n",
        "# trening modelu na zbiorze treningowym\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# test modelu na zbiorze testowym\n",
        "y_pr = model.predict(X_test)\n",
        "\n",
        "print(y_test[0])\n",
        "print(y_pr[0])\n",
        "\n",
        "# obliczenie i wyświetlenie wartości funkcji kosztu\n",
        "print(mean_squared_error(y_test, y_pr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219.0\n",
            "164.3739228754339\n",
            "3111.467828467563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1187: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS2QkufGgnnE"
      },
      "source": [
        "W tym miejscu przedstawię metodę treningu typu cross-validation. W skrócie metoda ta polega na określenie na ile grup dzielimy zbiór danych treningowych (najczęściej jest to 5) i następnie jedną z tych grup wybieramy jako zbiór walidacyjny pozostałe jako zbiór treningowy.\n",
        "\n",
        "Cały proces polega na treningu modelu na zbiorze treningowym i jego walidacji (ocenie skuteczności) na zbiorze walidacyjnym.\n",
        "Proces ten jest powtarzany n razy, gdzie n oznacza na ile grup dzielimy nasze dane. W kazdym kroku wybierana jest inna grupa danych jako zbiór walidacyjny.\n",
        "Po więcej informacji zapraszam do dokumentacji: [link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQSEXIM6goRX",
        "outputId": "2cf2dc68-adc5-4641-bdec-58c8995302a8"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Tworzymy obiekt klasy StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Tworzymy dwie listy na modele tworzone dla każdego kroku oraz na funkcję kosztu\n",
        "# wyliczoną na zbiorze walidacyjnym\n",
        "models = []\n",
        "errors = []\n",
        "\n",
        "# Główna pętla, metoda split odpowiada za proces kross-walidacji\n",
        "for train_index, val_index in skf.split(X_train, y_train):\n",
        "    model = SGDRegressor(max_iter=10000, tol=1e-3)\n",
        "    X_tr, y_tr = X_train[train_index], y_train[train_index]\n",
        "    X_val, y_val = X_train[val_index], y_train[val_index]\n",
        "\n",
        "    # Trening modelu\n",
        "    model.fit(X_tr, y_tr)\n",
        "    # Predykcja etykiet dla danych walidacyjnych\n",
        "    y_pr = model.predict(X_val)\n",
        "\n",
        "    # Obliczenie funkcji kosztu MSE dla danego kroku\n",
        "    errors.append(mean_squared_error(y_val, y_pr))\n",
        "    models.append(model)\n",
        "\n",
        "# Pobranie kroku, dla którego wartość funkcji kosztu była najmniejsza\n",
        "best_error_idx = np.argmin(errors)\n",
        "\n",
        "# Wybór tego modelu i błędu\n",
        "best_error = errors[best_error_idx]\n",
        "best_model = models[best_error_idx]\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Test najlepszego modelu na zbiorze testowym\n",
        "y_pr = best_model.predict(X_test)\n",
        "test_error = mean_squared_error(y_test, y_pr)\n",
        "\n",
        "print(\"Najniższy błąd modelu na zbiorze walidacyjnym {}\", best_error)\n",
        "print(\"Błąd modelu na zbiorze testowym {}\", test_error)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "[2606.734646298559, 3440.575519952246, 4175.912917226848, 2953.882798167365, 2316.6481970073414]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Najniższy błąd modelu na zbiorze walidacyjnym {} 2316.6481970073414\n",
            "Błąd modelu na zbiorze testowym {} 2828.142637582007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40_oCdWcS7p6"
      },
      "source": [
        "## ***Klasyfikacja***\n",
        "Celem klasyfikacji jest z kolei predykcja wartości dyskretnych\n",
        "Dla problemów klasyfikacji "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSW9K9g3YBwL"
      },
      "source": [
        "Tym razem wykorzystamy zbiór dany [iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris), przygotowany specjalnie dla algorytmów klasyfikacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z104O2xlmq_a",
        "outputId": "b99271c5-2b4f-45b9-c783-5f7691abf5bb"
      },
      "source": [
        "# Zaimportujmy zbiór danych przeznaczony do klasyfikacji\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "# Wyświetlmy parametry opisujące dane\n",
        "print(iris.feature_names)\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwM2x8-VnMkl"
      },
      "source": [
        "Podobnie jak w przypadku regresji najpierw sprawdźmy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqb1ruZlnM-i",
        "outputId": "b53f238a-be6d-4250-e873-7bbafcf87798"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model = SGDClassifier()\n",
        "# podział zbioru na zbiór treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
        "\n",
        "# trening modelu na zbiorze treningowym\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# test modelu na zbiorze testowym\n",
        "y_pr = model.predict(X_test)\n",
        "\n",
        "print(y_test[0])\n",
        "print(y_pr[0])\n",
        "\n",
        "# obliczenie i wyświetlenie wartości funkcji kosztu\n",
        "print(accuracy_score(y_test, y_pr))\n",
        "print(f1_score(y_test, y_pr, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "0.7\n",
            "0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pi9PWN7S5A8"
      },
      "source": [
        "### Hipoteza - funkcja logiczna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okrw4XuoTjUJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h-ZVQeXTjyZ"
      },
      "source": [
        "### Funkcja kosztu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUGCiFBMTnJW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHzt__PZTneC"
      },
      "source": [
        ""
      ]
    }
  ]
}